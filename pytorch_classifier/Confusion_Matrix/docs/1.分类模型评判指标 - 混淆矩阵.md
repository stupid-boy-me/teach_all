### 一、混淆矩阵Confusion Matrix

#### 1.1.一级指标（最底层的）：

真实值是positive，模型认为是positive的数量（True Positive=TP）

真实值是positive，模型认为是negative的数量（False Negative=FN）：这就是统计学上的第二类错误（Type II Error）

真实值是negative，模型认为是positive的数量（False Positive=FP）：这就是统计学上的第一类错误（Type I Error）

真实值是negative，模型认为是negative的数量（True Negative=TN）



#### 1.2.二级指标

但是，混淆矩阵里面统计的是个数，有时候面对大量的数据，光凭算个数，很难衡量模型的优劣。因此混淆矩阵在基本的统计结果上，通过最底层指标加减乘除得到二级指标：

  准确率（Accuracy）—— 针对整个模型

  精确率（Precision）

  灵敏度（Sensitivity）：就是召回率（Recall）

  特异度（Specificity）

  我用表格的方式将这四种指标的定义、计算、理解进行了汇总：

  ![](https://secure2.wostatic.cn/static/e5ebLm5K7GZHRPSiPndfqe/image.png?auth_key=1669178888-7ZKBDtBRyGy86w39pcqzbc-0-09101cf9d94ada309ed6e23c026c2972)

通过上面的四个二级指标，可以将混淆矩阵中数量的结果转化为0-1之间的比率。便于进行标准化的衡量。

上述均为二分类，多分类结果如下：

![](https://secure2.wostatic.cn/static/rMv6CeJPawRPJT6vbnP6GH/image.png?auth_key=1669178889-rJTeX5trtzazyAGoEsAJ7r-0-e1b4534472dd7669eee000b63e14332a)



#### 1.3.P-R曲线

![](https://secure2.wostatic.cn/static/kEKRvVwcvZxe1m2XNismVZ/image.png?auth_key=1669178889-8v471vDUPt7f84RdujbuHr-0-b007166b5aa0e0f2a8701587c1f79d3e)

PR图直观地显示出学习器在样本总体上的查全率、查准率。
  1. 在进行比较时，若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者，如图中学习器A的性能优于学习器C；
  2. 如果两个学习器的P-R曲线发生了交叉，如图中的A与B，则难以一般性地断言两者的优劣，只能在具体的查准率或查全率条件下进行比较。然而，在很多情形下，人们往往仍希望把学习器A与B比出个高低。这时一个比较合理的判据是比较P-R曲线下面积的大小，它在一定程度上表征了学习器在查准率和查全率上取得相对“双高”的比例。但这个值不太容易估算，因此，人们设计了一些综合考虑查准率、查全率的性能度量。平衡点就是这样一个度量。
  3. “平衡点”(Break-Even Point，简称BEP)就是这样一个度量，它是“查准率=查全率”时的取值，如图中学习器C的BEP是0.64，而基于BEP的比较，可认为学习器A优于B优于C。

  **但是基于平衡点度量，过于简单，更常采用的是F1_score。**

#### 1.4.三级指标 

**（1）F1_score** 

> 在这四个指标的基础上在进行拓展，会产令另外一个三级指标，这个指标叫做F1 Score，称为平衡F分数（BalancedScore），它被定义为正确率和召回率的调和平均数。它的计算公式是（P代表Precision（精确率也称查准率），R代表Recall（召回率也称查全率））：F1-Score指标综合了Precision与Recall的产出的结果。F1-Score的取值范围从0到1的，1代表模型的输出最好，0代表模型的输出结果最差。

**（2）Fβ_Score**

> Fβ的物理意义就是将正确率和召回率的一种加权平均，在合并的过程中，召回率的权重是正确率的β倍。β=1，认为recall和precision同等重要，即为F1-score；β>1，更看重recall，即看重模型对正样本的识别能力；β<1，则更看重precision，即看重模型对负样本的区分能力。　　
