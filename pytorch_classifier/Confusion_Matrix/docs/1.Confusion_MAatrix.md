- **1.混淆矩阵**

  - **一级指标(最底层的)**

    - TP

      真正类：**样本的真实类别是正类，并且模型识别的结果也是正类**。

    - FN

      假负类：样本的真实类别是正类，但是模型将其识别为负类。

    - FP

      假正类：样本的真实类别是负类，但是模型将其识别为正类。

    - TN

      真负类：**样本的真实类别是负类，并且模型将其识别为负类**。

||预测 Prediction|预测 Prediction|预测 Prediction|
|-|-|-|-|
|实际 True|类1|类2|类3|
|类1|43|2|0|
|类2|5|45|1|
|类3|2|3|49|


  1. 每一行之和表示该类别的真实样本数量，每一列之和表示被预测为该类别的样本数量
  2. 第一行第一列中的43表示有43个实际归属第一类的实例被预测为第一类，同理，第一行第二列的2表示有2个实际归属为第一类的实例被错误预测为第二类。

  ### 从混淆矩阵得到分类指标

  - **二级指标**

    - 准确率（Accuracy）—— 针对整个模型

      精确率是最常用的分类性能指标。可以用来表示模型的精度，即模型识别正确的个数/样本的总个数。一般情况下，模型的精度越高，说明模型的效果越好。

$$
Accuracy = (TP+TN)/(TP+FN+FP+TN)
$$

    - 精确率（Precision）

      又称为查准率，表示在模型识别为**正类的样本**中，真正为正类的样本所占的比例。一般情况下，查准率越高，说明模型的效果越好。

$$
Precision = TP/(TP+FP)
$$

    - 灵敏度（Sensitivity）：就是召回率（Recall）= TPR

      又称为查全率，召回率表现出在实际正样本中，分类器能预测出多少。表示的是，模型正确识别出为正类的样本的数量占总的正类样本数量的比值。一般情况下，Recall越高，说明有更多的正类样本被模型预测正确，模型的效果越好。

$$
Recall = TP/(TP+FN)
$$

      

      > 查准率和查全率是一对矛盾的指标。一般来说，查准率高时，查全率旺旺偏低；二查全率高时，查准率往往偏低。

    - 特异度（Specificity）

      特异性指标，表示的是模型识别为负类的样本的数量，占总的负类样本数量的比值。

      负正类率（False Positive Rate, FPR），计算公式为：

$$
FPR=FP/(TN+FP)
$$

      计算的是模型错识别为正类的负类样本占所有负类样本的比例，一般越低越好。

$$
Specificity = 1 - FPR
$$

    - P-R曲线

      ![](https://secure2.wostatic.cn/static/kEKRvVwcvZxe1m2XNismVZ/image.png)

      PR图直观地显示出学习器在样本总体上的查全率、查准率。
        1. 在进行比较时，若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者，如图中学习器A的性能优于学习器C；
        2. 如果两个学习器的P-R曲线发生了交叉，如图中的A与B，则难以一般性地断言两者的优劣，只能在具体的查准率或查全率条件下进行比较。然而，在很多情形下，人们往往仍希望把学习器A与B比出个高低。这时一个比较合理的判据是比较P-R曲线下面积的大小，它在一定程度上表征了学习器在查准率和查全率上取得相对“双高”的比例。但这个值不太容易估算，因此，人们设计了一些综合考虑查准率、查全率的性能度量。平衡点就是这样一个度量。
        3. “平衡点”(Break-Even Point，简称BEP)就是这样一个度量，它是“查准率=查全率”时的取值，如图中学习器C的BEP是0.64，而基于BEP的比较，可认为学习器A优于B优于C。

        **但是基于平衡点度量，过于简单，更常采用的是F1_score。**

  - **三级指标**

    Fβ的物理意义就是将正确率和召回率的一种加权平均，在合并的过程中，召回率的权重是正确率的β倍。***F1分数认为召回率和正确率同等重要***，F2分数认为召回率的重要程度是正确率的2倍，而F0.5分数认为召回率的重要程度是正确率的一半。比较常用的是F1分数（F1 Score），是统计学中用来衡量二分类模型精确度的一种指标。***F1-Score的值是从0到1的，1是最好，0是最差。***

    - **F1_score** 

      > 在这四个指标的基础上在进行拓展，会产令另外一个三级指标，这个指标叫做F1 Score，称为平衡F分数（BalancedScore），它被定义为正确率和召回率的调和平均数。它的计算公式是（P代表Precision（精确率也称查准率），R代表Recall（召回率也称查全率））：F1-Score指标综合了Precision与Recall的产出的结果。F1-Score的取值范围从0到1的，1代表模型的输出最好，0代表模型的输出结果最差。

    - **Fβ_Score**

      Fβ的物理意义就是将正确率和召回率的一种加权平均，在合并的过程中，召回率的权重是正确率的β倍。β=1，认为recall和precision同等重要，即为F1-score；β>1，更看重recall，即看重模型对正样本的识别能力；β<1，则更看重precision，即看重模型对负样本的区分能力

  #### 混淆矩阵总结：

  Precision，Recall，Specificity等只是计算某一分类的特性，而Accuracy和F1-Score是判断分类模型总体的标准

